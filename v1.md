# Lock PDF + URL Agent v1

> **Version:** v1 (Locked)
>
> **Status:** Scope frozen
>
> **Goal:** Create a backend-free, personal agent that can ingest a small PDF or a single webpage, collapse it into a clean local summary, and allow voice-based Q&A grounded strictly in that content.

---

## 1. Purpose

Lock PDF + URL Agent v1 is a **personal, single-context conversational agent** designed for everyday individual use.

The app allows the user to:

* Upload a small PDF **or** paste a single URL
* Convert the content into Markdown or plain text
* Generate a concise, structured summary
* Ask spoken questions about that summary
* Receive spoken answers grounded **only** in that document

This version is intentionally small to ensure:

* Fast responses
* Predictable behavior
* A finishable, production-grade app

---

## 2. Non-Goals (Explicitly Out of Scope)

The following are **not supported in v1**:

* Large PDFs (e.g. textbooks, manuals)
* Chunking or pagination handling
* Multi-document ingestion
* Search, crawling, or deep linking
* Embeddings or vector databases
* Long-term or cross-session memory
* Background processing
* External knowledge augmentation
* Cloud backends or user accounts

Anything outside the defined limits must be **explicitly rejected**.

---

## 3. Input Constraints (Hard Limits)

### 3.1 PDF Constraints

* **Maximum file size:** 2MB (proxy for ~20 pages of typical text PDFs)
* **Processing method:** Direct upload to Gemini File API
* **Content type:** Any PDF (text, scanned, images - Gemini handles natively with OCR)
* **Behavior on exceed:** Reject before upload

**Why file size instead of page count?**
- Can't count pages without parsing PDF on-device
- 2MB covers ~20 pages of typical text PDFs  
- Simpler, faster validation (instant)
- Gemini File API handles extraction natively (better quality)

Example rejection message:

> "This PDF is too large for v1. Please upload a smaller document (max 2MB)."

---

### 3.2 URL Constraints

* Single webpage only
* No pagination
* No internal or external link following
* **Maximum Markdown length:** ~15,000 characters
* **Conversion method:** URL → Markdown

Conversion is performed using:

```ts
const response = await fetch(
  "https://www.urltoany.com/api/function/to-markdown",
  {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ url })
  }
);
```

The resulting Markdown is the **only input** passed to the model.

Example rejection message:

> "This webpage is too large or complex for v1."

---

## 4. Architecture (Locked)

* **Backend:** None (100% client-side)
* **Network calls:**

  * URL → Markdown API
  * Gemini API (direct)
* **Persistence:** `expo-sqlite`
* **Active context:** Exactly one document at a time

New ingestion **overwrites** the previous context.

No cloud sync. No auth. No servers.

---

## 5. Supported Models

| Role                | Model                   |
| ------------------- | ----------------------- |
| Summarization & Q&A | `gemini-2.5-flash-lite` |
| Text-to-Speech      | `gemini-2.5-flash-tts`  |

The system operates as a **single logical agent** with sequential model calls.

---

## 6. Processing Flow

### 6.1 Ingestion Flow

```
User uploads PDF / pastes URL
↓
Validate size & constraints (file size for PDF, char count for URL)
↓
PDF → Upload to Gemini File API (native processing)
URL → Markdown conversion
↓
Summarization (Gemini Flash-Lite)
↓
Structured summary stored in SQLite
```

---

### 6.2 Conversation Flow

```
User speaks question
↓
Speech-to-text
↓
Context-bound Q&A (Gemini Flash-Lite)
↓
Answer text
↓
Text-to-speech (Gemini Flash-TTS)
↓
Audio playback
```

---

## 7. Context Creation

### 7.1 Summarization Prompt (v1)

```text
You are summarizing a document for conversational use.

Produce:
- A short overview
- 5–10 key points
- Important definitions or concepts (if any)

Use only the provided content.
Do not add external knowledge.
Keep the output concise and factual.
```

---

### 7.2 Context Storage Schema

```json
{
  "title": "Document Title",
  "source": "pdf | url",
  "overview": "...",
  "key_points": ["...", "..."],
  "definitions": ["..."]
}
```

This object is:

* The **only** knowledge source
* The **only** context for Q&A
* Persisted locally via SQLite

---

## 8. Q&A Rules (Strict)

The agent must follow these rules:

* Answer **only** using the stored summary
* Do not infer or guess beyond the summary
* Do not introduce external facts
* If the answer is not present:

```text
"I don’t see that in this document."
```

Responses must be:

* Short
* Clear
* Spoken-language friendly

---

## 9. Error Handling

All failures must be **explicit and user-visible**.

| Scenario                   | Behavior |
| -------------------------- | -------- |
| PDF too large              | Reject   |
| URL too large              | Reject   |
| Unsupported PDF            | Reject   |
| Empty / unreadable content | Reject   |

No silent truncation.
No partial ingestion.

---

## 10. UI Scope (Production-Grade)

The UI is built using **`heroui-native`** components for a clean, production-ready feel.

### Screen 1: Ingestion

* PDF upload or URL input
* Primary "Process" button
* Clear validation and error states

### Screen 2: Conversation

* Push-to-talk microphone
* Automatic audio playback
* Optional text transcript

No conversation history UI.
No settings screen.

---

## 11. Version Lock Statement

> **This document defines v1.**
>
> Any feature not explicitly listed here is deferred to v2.
>
> v1 exists to validate interaction quality, not scale.

---

## 12. Planned v2 (Deferred)

* Large document chunking
* Textbook-scale ingestion
* Multi-source context
* Retrieval-based Q&A
* Persistent multi-document memory
* Advanced voice controls

---

**End of v1 Specification**
